# 폴더 내 파일 설명

| 파일명 | 내용 |
|---------|--------|
| <b>`mobiilenetv2_final.ipynb`</b>    |   PyTorch를 사용해 이미지 분류 모델(MobileNetV2)을 학습하고, 학습 과정에서 발생한 손실 값을 그래프로 시각화한 후 모델을 저장      |
| <b>`mobiilenetv2_test.py`</b>  |  MobileNetV2 모델을 로드하여 테스트 데이터셋에 대해 평가를 수행하고, 전체 정확도와 손실, 그리고 각 클래스별 정확도 및 평균 손실을 출력     |
| <b>`models_comparison.py`</b>  |   VGG16, ResNet50, MobileNetV2 모델의 추론 속도와 메모리 사용량을 측정하여 출력<br> 각 모델에 대해 임의의 데이터를 사용해 성능을 비교     |
| <b>`trained_model_final.pt`</b>  |   학습이 완료된 PyTorch 모델의 가중치 파일    |

-----

# 3. 모델 선정

## 🔶 YOLOv5

- **설명**
    - ‘YOLO’는 ‘You Only Look Once’의 약자로, PyTorch를 기반으로 하며, 컴퓨터 비전 태스크에서 **객체 탐지(Object Detection)**를 위한 딥러닝 알고리즘이다.
    - YOLO는 이미지를 그리드로 나누고, 각 그리드 셀에서 객체의 경계 상자(bounding box)와 클래스를 예측한다.
- **선정 이유**
    - ‘YOLO’를 이용하여 실시간으로 **Object Detection**을 진행할 수 있으며, CNN모델로 학습할 클래스의 개수를 일차적으로 YOLOv5를 사용함으로써 줄일 수 있다.
- **활용**
    - 소주병과 맥주병을 ‘bottle’로 인식하였기에, 이를 그대로 활용하였다.
    - 소주잔과 맥주잔을 ‘wine glass’혹은 ‘cup’으로 인식한 것을 그대로 활용하여, 이 두 가지 클래스 중 하나로 인식할 경우 MobileNetV2를 활용해 재분류를 진행하였다.

## 🔶 MobileNetV2

- **설명**
    - 모바일 기기나 에지 디바이스에서 사용하기 위해 경량화된 CNN 아키텍처 모델이다.
    - Depthwise Separable Convolution 등의 기술을 활용하여 빠르고 효율적으로 동작한다.
    - 높은 성능을 유지하면서도 낮은 연산 비용과 메모리 사용량을 가지고 있어, 리소스가 제한된 환경에서 효과적으로 사용된다.
- **선정 이유**
    - **VGG-16**, **ResNet-50** 및 **MobileNetV2**: **이미지 분류(Classification)**, 객체 분할, 특성 추출 및 전이 학습 목적으로 사용되는 CNN 모델
    - 위 두 가지 모델과 비교하였을 때 경량화, 빠른 속도, 저전력 소비, 전이학습 가능, 이미지 분류에 적합하다는 특성이 있음.
    - 문헌철 외 2인에 따르면, 별도의 압축 알고리즘이 적용되지 않은 각각의 원본 CNN 모델의 성능은 다음과 같다.

        ![모바일넷v2_1](https://github.com/user-attachments/assets/90febb80-4fbc-4e97-94b6-d0e50e36101d)

- 본 프로젝트에 활용될 데이터 특성
    - **이미지 데이터셋의 수** : 클래스별 200개
    - **클래스 수** : 3개
    - **이미지 전송 방식** : 실시간으로 전송하고 처리(stream) → 빠른 실시간 출력
- 모델로부터 예측된 클래스 중 상위 5개에 정답이 있을 경우의 **정확도**(Top-5 Accuracy)를 비교해보면 가장 높은 RestNet50과 MobileNetV2의 정확도 차이는 *1.87%p*로 비슷한 수치를 나타냈다.
- 이 중에서도 높은 정확도를 유지하면서도 최소한의 리소스를 사용하며, 가장 빠른 추론 속도를 갖는 **MobileNetV2** 모델을 선택하였다.
- 위와 같은 결정의 타당성을 검증하기 위해 직접 세 가지 모델의 **추론 속도**와 **메모리 사용량**을 측정하는 코드를 구현하여 확인하였다.

    ![모델사용량측정](https://github.com/user-attachments/assets/958fc46e-4e36-42ea-8140-4a68433afc6e)

- CNN 모델의 추론 속도와 메모리 사용량 비교 결과
    - **추론 속도** : VGG-16(170초) **>** ResNet-50(59초) **>** MobileNetV2(15초)
        
        (3개의 클래스, 600개의 이미지)
        
    - 이미지 데이터 개수가 적어서 리소스 사용량의 차이는 무의미함.
    - **MobileNetV2** 모델은 실시간 추론이 필요하고, 적은 수의 클래스, 데이터셋의 크기가 적으며, 컴퓨팅 리소스가 제한적인 경우에 **적합**하다는 결론을 내릴 수 있다.
- **활용**
    - YOLOv5에서 ‘wine glass’ 혹은 ‘cup’으로 인식된 소주잔, 맥주잔, 나머지 종류의 컵 이미지가 주어졌을 때 이를 분류하는 작업을 진행하였다.

-----

# 4. 모델 학습

## 1) 학습 요약

- Google Colab에서 구글 드라이브를 마운트하고 train과 validation 데이터셋을 불러왔다.
- MobilnetV2 모델을 불러와서 클래스를 3개(컵, 맥주잔, 소주잔)으로 변경하고 전이학습을 진행하였다.
- 각 **epoch별** 학습 소요시간 및 train과 validation **손실과 정확도**를 기록하고, 학습 과정 중 각 **step별** 손실을 시각화하여 나타내었다.

## 2) 데이터셋 구성

![학습데이터셋003003](https://github.com/user-attachments/assets/00b23371-f95a-4c1a-a616-ea78226e8442)


## 3) 초기 학습

![Untitled2](https://github.com/user-attachments/assets/6f1850ff-aac6-4f62-bc51-fa44ffc74f2c)

- train과 validation 이미지를 **7:3**의 비율로 나눔.
- Epochs = **100**
- Learning Rate = **0.0001**
- 학습 결과, 다음과 같은 **문제**가 발생함.
    - 클래스마다 데이터 수가 충분하지 않아 7:3의 비율로 나눌 경우, train 데이터의 양이 절대적으로 부족하게 됨. → *train과 validation 이미지수 비율을 조정함.*
    - 30 epoch 이후 과적합 경향이 나타남.  **→** *에폭 수를 낮추기로 함.*
    - 그래프를 통해 step별 loss의 변동폭이 큰 것을 확인함.  **→** *학습률을 낮춰서 안정적으로 최적화되도록 함.*

## 4 ) 최종 학습

- train과 validation 이미지를 **9:1**의 비율로 나눔.  (train 이미지수 ↑, train 이미지 argumentation)
- Epochs = **30**  (에폭 ↓)
- Learning Rate = **0.00001**  (학습률 ↓)

### 학습 모델의 정확도 차이와 수렴 확인

![최종학습결과](https://github.com/user-attachments/assets/5edada88-a37e-4929-b355-561e06f43c50)

- 초기에는 Train 데이터와 Validation 데이터 간의 **정확도 차이**가 약 20% 포인트였으나, 30 에폭이 되어가면서 이 차이가 0.0015% 포인트로 **매우 감소**하고 있음을 확인할 수 있다.
- 이것은 모델이 점차 학습을 통해 **더 정확한 예측**을 하고 있으며, 특히 마지막 epoch에 가까워질수록 이러한 경향이 더 뚜렷해진다는 것을 알 수 있다. 이로써 모델이 잘 **수렴**하고 있다는 것을 확인하였다.

### 학습 모델의 손실 감소 추이

![loss (1) (1)](https://github.com/user-attachments/assets/a9b66fd4-8282-4fcb-957e-374623c40252)

- **Loss**는 모델의 예측값과 실제 값 사이의 차이를 나타낸다.
- 일반적으로 Loss가 낮을수록 모델이 데이터를 더 잘 학습한다는 것을 의미한다.
    - **Training Loss**
        - 모델이 학습 데이터에 얼마나 적합하게 학습 되었는지를 나타낸다.
        - Training Loss가 **감소**하면, 모델은 학습 데이터에 잘 적합하게 되는 것이다.
    - **Validation Loss**
        - 모델이 학습하지 않은 데이터에 대해서 얼마나 잘 일반화할 수 있는지를 나타낸다.
        - Validation Loss가 **감소**하면, 모델이 더 **일반화된 데이터에서** 예측하는 성능이 높아지는 것으로 볼 수 있다.
- Loss가 지속적으로 감소하는 것은 모델이 데이터를 잘 학습하고 있다는 신호이다.  만약 Training Loss만 계속해서 감소하고 Validation Loss가 증가한다면, 이는 **과적합**을 의미할 수 있다.
- 그러나 위 모델의 학습 결과를 살펴보면, 마지막 epoch에 가까워질수록 Training Loss와 Validation Loss가 **모두 감소**하였다. 이는 모델이 **새로운 데이터**에 대해서도 잘 **일반화**되었음을 나타내며, 일반화할 수 있는 학습이 완료되었음을 알 수 있다.

-----

# 5. 모델 평가

## 1) Test 데이터셋 구성

![Untitled3](https://github.com/user-attachments/assets/6faf1253-e3c3-4a16-bc29-c0245122b1b9)

## 2) Test 결과

![Untitled4](https://github.com/user-attachments/assets/32a7c7fb-a531-4add-9325-a8a2b30e17df)

### 전체 학습 정확도와 손실

- 전이 모델의 3차(최종) 학습 결과는 **train** 손실은 0.1891이며 정확도는 93.39%이고, **validation** 손실은 0.2279, 정확도는 93.24%이다.
- 하지만 테스트 결과 **전체 데이터** **정확도**는 약 12%p 정도 낮아졌고, **손실**은 검증 손실과 비슷한 수준으로 나왔다.

### 클래스별 정확도와 평균 손실 분석

- **클래스별**로 정확도와 평균 손실을 살펴보면, **컵 클래스**의 정확도가 가장 낮고(72%) 평균 손실이 가장 높음(0.5885)을 확인할 수 있다.
- 평균 손실이 높다는 것은 모델이 학습 데이터에서 더 많은 오류를 만든다는 것을 나타낼 수 있다. 이는 모델이 데이터를 제대로 학습하지 못했거나, 데이터가 불균형하거나, 다른 이유로 인해 발생할 수 있다.
- 또한, **맥주잔과 소주잔을 비교**해보았을 때 **맥주잔**의 **정확도**가 낮고 **손실**이 높게 나왔다. 소주잔의 형태는 상대적으로 일정한 특성을 띄고 있는 반면, 맥주잔의 형태는 머그, 바이젠, 플루트, 필스너 등 다양한 종류로 구성되어 있으며, 손잡이의 유무와 곡률, 길이 등이 다양하게 나타난다. 이러한 이유로 맥주잔 클래스에서 높은 손실과 낮은 정확도가 나타난 것으로 추정된다.

### 모델 사용 여부

- 결론적으로, 컵과 맥주잔 클래스에서는 **더 많은 양**의 학습 및 테스트 **데이터가 필요함**을 알 수 있다. 이러한 부족함이 있음에도 불구하고 **전이학습한 모델을 사용**하기로 결정하였다.
- 이 모델의 주된 목적은 깨지기 쉬운 유리잔을 감별하는 것이므로, 맥주잔의 정확도가 약 80%이고 소주잔의 정확도가 95%로, 컵 클래스에 비해 **상대적으로 높은 정확도**를 보였으며, 이는 **모델의 학습 목적에 부합**하기 때문이다.