# 폴더 내 파일 설명

| 파일명 | 내용 |
|---------|--------|
| <b>`desk_edge_save.py`</b>   |   주어진 이미지에서 엣지 검출 및 선 검출을 수행하여, 검출된 선들을 원본 이미지에 그린 후, 선의 좌표를 파일에 저장하고 결과 이미지를 화면에 표시       |
| <b>`edge_detection.py`</b> |   두 개의 선(Line 1, Line 2)을 정의하고, 주어진 좌표(x, y)가 두 선 사이에 있는지 확인하는 alarm 함수를 구현하여 특정 조건을 만족할 때 True를 반환    |
| <b>`glass_defender.py`</b>  |   - YOLOv5 모델을 사용하여 객체 탐지를 수행하고, 탐지된 객체의 이미지에서 특정 물체를 분류하기 위해 MobileNetV2 모델을 활용 <br> - 또한, 위험 물체가 감지되면 서버로 알람을 보내는 기능을 포함    |

# 6. MobileNetV2와 YOLOv5 환경 통합

## 1) 데이터 전처리를 위한 변환 정의

- YOLOv5 모델로 감지된 이미지의 x, y 좌표 추출
- 프레임마다 이미지를 담는 변수에 x, y 좌표를 넣어서 이미지를 자른다.
- 자른 이미지는 **Numpy** 형식이다.
- 이를 **MobileNetV2**에 넣어서 **재인식**하고 **분류**하기 위해서는 다음과 같은 단계를 거친다.
1. 이미지 크기를 조정한다.
2. 이미지 중앙 부분을 잘라낸다.
3. 이미지를 pytorch 텐서로 변환한다.
4. 전이학습된 MobileNetV2에 맞게 정규화 한다.

## 2) CPU 환경에서 실행하기 위해 pytorch의 device를 CPU로 설정

- 주의할 점은, 모델을 불러와서 사용함에 있어서 이미지를 불러올 때마다 <b>모델을 새로 로드하지 않아야 한다는 것</b>이다.
- 프로젝트의 목표는 실시간 실행이지만, 이 방식으로는 테이블 위 물체를 판별하는 속도가 느려질 수 있기 때문이다.

# 7. 테이블 윤곽선과 RedLine 화면 출력

- **OpenCV2**를 활용하여 테이블 윤곽선 검출 후, 이와 RedLine을 실시간으로 화면에서 나타나도록 하였다.

## **Gaussian Blur**

- 가우시안 블러는 이미지를 흐리게 만들지만 이미지의 엣지와 구조를 보존하는 특성이 있다.
- 이는 노이즈를 감소시키면서도 객체의 전반적인 모양과 구조를 유지하고자 할 때 유용하다.
- 따라서, 테이블의 윤곽선을 추출하는 데 적합하였다.

## Canny

- 이미지에서 정확한 에지를 식별하는 데 효과적이며, 노이즈나 미묘한 디테일에 영향을 받지 않고 이미지의 주요 특징을 추출할 수 있어서 사용하였다.

## **HoughLine**

- 허프 라인 변환은 이미지에서 직선 모양의 패턴을 탐지하는 데 사용할 수 있다.
- 허프 라인 변환을 통해 감지된 직선을 통해 책상 윤곽선을 추출할 수 있었다.

## **RedLine 검출**

- 맥주병을 기준으로 **테이블**의 **모서리** 쪽에 놓았을 때를 **위험 상황**으로 설정하였다.
- 좌표를 4개를 구해서, 직선의 방정식으로 3개의 선분을 구했다.
- **3개의 선분**을 구한 뒤 이를 연결하여, 화면에 나타내는 코드를 완성하였다.

## 실시간 실행

- 선분의 방정식을 화면에 그대로 나타내는 것은 적합하지 않은 접근이었다.
- 대신 <b>좌표</b>들을 구하여, <b>이를 잇는 직선들</b>을 cv2를 활용해 실시간으로 화면에 나타냈다.

# 8. 서버(노트북), 클라이언트(라즈베리파이) 연결 및 최종 구동

## 라즈베리파이 환경에서 웹 카메라 구동

- 프로젝트 목표에 따르면 라즈베리파이 어플리케이션(클라이언트)의 역할을 하기 때문에, <b>카메라는 라즈베리파이에서 연결되어 실행</b>되어야 한다.
- 이에 따라 웹 카메라를 라즈베리파이에 연결하고, 이를 통해 <b>실시간 스트림 서버</b>를 구축한 뒤, <b>노트북의 PyCharm에서 서버 주소를 받아와서 실행</b>하였다.
- 로딩 과정에서 약간의 지연이 발생하였다.

## LED 구동

- Flask를 이용하여 라즈베리파이를 서버로, 노트북을 클라이언트로 설정하여 통신을 하였다.
- **위험상황**은 앞서 설명한 대로 책상의 가장자리에 해당하는 **RedLine**에 물체가 닿았을 경우를 의미한다.
- 플래그를 활용하여 실시간으로 탐지된 물체들 중 **위험 상황**이 발생한 물체가 **하나라도 있는** 경우, LED 등에 **빨간 빛**이 들어오도록 설정하였다.
- 위험 상황이 아닌 **평상시**의 경우 **초록 빛**을 켜도록 설정하였다.

## 프로젝트 시연 모습

![보고서용사진최종](https://github.com/user-attachments/assets/521a87b8-5529-4247-b629-50d65c5c58ac)

좌측부터 1) RedLine을 벗어난 위험 상황에서의 빨간 빛 / 2) 평상시 초록 빛 / 3) 화면 내 YOLOv5의 객체탐지 